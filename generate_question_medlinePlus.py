import json
import os
from tqdm import tqdm
from vllm import LLM, SamplingParams

# --- Cáº¤U HÃŒNH ---
# Sá»­ dá»¥ng model máº¡nh vá» Ä‘a ngÃ´n ngá»¯ vÃ  y táº¿
MODEL_ID = "Qwen/Qwen2.5-32B-Instruct-AWQ"
INPUT_FILE = 'data_medlineplus_vi.json'   # File dá»¯ liá»‡u MedlinePlus cá»§a báº¡n
OUTPUT_FILE = 'train_dataset_medlineplus.jsonl'

# Cáº¥u hÃ¬nh VLLM
llm = LLM(
    model=MODEL_ID,
    quantization="awq",
    dtype="half",
    gpu_memory_utilization=0.9,
    max_model_len=4096,
    enforce_eager=True
)

# Cáº¥u hÃ¬nh sinh vÄƒn báº£n (Temperature tháº¥p hÆ¡n chÃºt Ä‘á»ƒ bÃ¡m sÃ¡t sá»± tháº­t y khoa)
sampling_params = SamplingParams(
    temperature=0.6,
    top_p=0.9,
    max_tokens=1500,
    stop=["<|im_end|>", "<|endoftext|>"]
)

def make_cross_lingual_prompt(title, content):
    """
    Prompt Ä‘áº·c biá»‡t: Input tiáº¿ng Anh (hoáº·c Viá»‡t) -> Output báº¯t buá»™c Tiáº¿ng Viá»‡t.
    """
    return f"""<|im_start|>system
Báº¡n lÃ  chuyÃªn gia y táº¿ song ngá»¯ Anh-Viá»‡t. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  táº¡o dá»¯ liá»‡u huáº¥n luyá»‡n cho mÃ´ hÃ¬nh AI y táº¿ Viá»‡t Nam.<|im_end|>
<|im_start|>user
Dá»±a trÃªn thÃ´ng tin dÆ°á»›i Ä‘Ã¢y tá»« MedlinePlus:

**Chá»§ Ä‘á»:** {title}
**Ná»™i dung:** "{content[:3500]}"

YÃŠU Cáº¦U:
1. Táº¡o 4-6 nháº­n Ä‘á»‹nh (statement) báº±ng **TIáº¾NG VIá»†T**.
2. Äáº£m báº£o 50% lÃ  nháº­n Ä‘á»‹nh ÄÃšNG (True), 50% lÃ  nháº­n Ä‘á»‹nh SAI (False).
3. Nháº­n Ä‘á»‹nh pháº£i dá»±a hoÃ n toÃ n vÃ o ná»™i dung cung cáº¥p, khÃ´ng bá»‹a Ä‘áº·t.
4. Vá»›i cÃ¢u SAI, hÃ£y sá»­a Ä‘á»•i má»™t chi tiáº¿t quan trá»ng (vÃ­ dá»¥: nguyÃªn nhÃ¢n, triá»‡u chá»©ng, tÃªn thuá»‘c) Ä‘á»ƒ lÃ m nÃ³ sai.
5. Tráº£ vá» Ä‘á»‹nh dáº¡ng JSON List chÃ­nh xÃ¡c: [{{ "input": "...", "output": "..." }}]
<|im_end|>
<|im_start|>assistant
"""

def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {INPUT_FILE}")
        return

    # 1. Äá»c dá»¯ liá»‡u Ä‘áº§u vÃ o
    print("ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u MedlinePlus...")
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
        # Xá»­ lÃ½ trÆ°á»ng há»£p data lÃ  dict hoáº·c list
        if isinstance(data, dict) and 'feed' in data: # Cáº¥u trÃºc thÆ°á»ng tháº¥y cá»§a XML Medline convert sang JSON
            data = data['feed'].get('entry', [])
        elif isinstance(data, dict):
            data = [data]

    all_prompts = []
    metadata = []

    # 2. Táº¡o Prompt
    print("âš™ï¸ Äang táº¡o prompt...")
    for item in tqdm(data):
        # Mapping trÆ°á»ng dá»¯ liá»‡u (Báº¡n cáº§n sá»­a láº¡i key cho khá»›p file JSON cá»§a báº¡n)
        # MedlinePlus thÆ°á»ng cÃ³: title, summary, content, hoáº·c description
        title = item.get('title', {}).get('#text', '') if isinstance(item.get('title'), dict) else item.get('title', 'Y táº¿')

        # Láº¥y ná»™i dung: Æ°u tiÃªn content dÃ i, náº¿u khÃ´ng cÃ³ thÃ¬ láº¥y summary
        content = item.get('content', {}).get('#text', '') if isinstance(item.get('content'), dict) else item.get('content', '')
        if not content:
            content = item.get('summary', {}).get('#text', '') if isinstance(item.get('summary'), dict) else item.get('summary', '')

        # Bá» qua náº¿u ná»™i dung quÃ¡ ngáº¯n
        if len(str(content)) < 100: continue

        prompt = make_cross_lingual_prompt(title, content)
        all_prompts.append(prompt)
        metadata.append({"source": "MedlinePlus", "topic": title})

    print(f"ğŸ“¦ Tá»•ng sá»‘ prompt cáº§n cháº¡y: {len(all_prompts)}")

    # 3. Cháº¡y Inference (Batch)
    print("ğŸš€ Báº¯t Ä‘áº§u sinh dá»¯ liá»‡u...")
    outputs = llm.generate(all_prompts, sampling_params)

    # 4. LÆ°u káº¿t quáº£
    valid_count = 0
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f_out:
        for i, output in enumerate(outputs):
            generated_text = output.outputs[0].text
            meta = metadata[i]

            try:
                # TrÃ­ch xuáº¥t JSON tá»« text sinh ra
                start = generated_text.find('[')
                end = generated_text.rfind(']') + 1

                if start != -1 and end != -1:
                    qa_list = json.loads(generated_text[start:end])

                    for qa in qa_list:
                        inp = qa.get('input', '')
                        out = qa.get('output', '')

                        # Kiá»ƒm tra xem output cÃ³ pháº£i tiáº¿ng Viá»‡t khÃ´ng (sÆ¡ bá»™)
                        # Náº¿u output váº«n lÃ  tiáº¿ng Anh thÃ¬ bá» qua (hoáº·c lá»c sau)
                        if len(inp) < 10: continue

                        final_obj = {
                            "instruction": f"XÃ¡c Ä‘á»‹nh tÃ­nh ÄÃºng/Sai cá»§a nháº­n Ä‘á»‹nh sau dá»±a trÃªn kiáº¿n thá»©c vá» {meta['topic']}.",
                            "input": inp,
                            "output": str(out).upper(), # Chuáº©n hÃ³a TRUE/FALSE
                            "source_type": "MedlinePlus",
                            "topic": meta['topic']
                        }

                        json.dump(final_obj, f_out, ensure_ascii=False)
                        f_out.write('\n')
                        valid_count += 1
            except Exception as e:
                continue

    print(f"\nâœ… HOÃ€N Táº¤T! ÄÃ£ sinh Ä‘Æ°á»£c {valid_count} cÃ¢u há»i tiáº¿ng Viá»‡t tá»« MedlinePlus.")
    print(f"LÆ°u táº¡i: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()